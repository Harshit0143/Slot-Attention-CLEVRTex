{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9a817aa",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-06T10:22:52.481718Z",
     "iopub.status.busy": "2024-05-06T10:22:52.481432Z",
     "iopub.status.idle": "2024-05-06T10:22:57.994849Z",
     "shell.execute_reply": "2024-05-06T10:22:57.993871Z"
    },
    "papermill": {
     "duration": 5.52011,
     "end_time": "2024-05-06T10:22:57.997011",
     "exception": false,
     "start_time": "2024-05-06T10:22:52.476901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's Go!\n",
      "torch version: 2.1.2\n"
     ]
    }
   ],
   "source": [
    "print(\"Let's Go!\" )\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from torch.optim import Adam\n",
    "import random \n",
    "from torch.nn import ReLU\n",
    "from torch.nn import LayerNorm\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.init import xavier_uniform_\n",
    "from torch.nn import BatchNorm2d\n",
    "from torch.nn import Parameter\n",
    "from torch.nn import Linear\n",
    "from torch.nn import DataParallel\n",
    "from torch.nn import Sequential\n",
    "from torch.nn import ConvTranspose2d\n",
    "from torch.nn import GRUCell\n",
    "from torch.nn import Module\n",
    "from torch.nn import Flatten\n",
    "from torch.nn.init import normal_\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.functional import softmax\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Conv1d\n",
    "from torch.nn import MSELoss\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import h5py\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "from torchvision.transforms import InterpolationMode\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "print(\"torch version:\" , torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3189be12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T10:22:58.005462Z",
     "iopub.status.busy": "2024-05-06T10:22:58.005069Z",
     "iopub.status.idle": "2024-05-06T10:23:29.119220Z",
     "shell.execute_reply": "2024-05-06T10:23:29.118002Z"
    },
    "papermill": {
     "duration": 31.120591,
     "end_time": "2024-05-06T10:23:29.121345",
     "exception": false,
     "start_time": "2024-05-06T10:22:58.000754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices shape: (5319,)\n",
      "Loading data!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5319/5319 [00:30<00:00, 172.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data!\n",
      "data size: 5319\n",
      "image tensor max-min 0.8588235378265381 -0.9843137264251709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "images_val = '/kaggle/input/clevertex6-val/CLEVERTex6_val/CLEVERTex6_val_images'\n",
    "clever6_indices_path = '/kaggle/input/clevertex6-val/CLEVERTex6_val/CLEVRTex6_val_indices.npy'\n",
    "clever6_indices = np.load(clever6_indices_path)\n",
    "class ImageDatasetSlotAttention(Dataset):\n",
    "    def __init__(self, images_folder , indices , transform):\n",
    "        super(ImageDatasetSlotAttention , self).__init__()\n",
    "        self.images_folder = images_folder\n",
    "        self.transform = transform\n",
    "        self.indices = indices\n",
    "        print(\"indices shape:\" , self.indices.shape)\n",
    "        self.all_data =  self.build_data(images_folder)\n",
    "        print(\"data size:\" , len(self.all_data))\n",
    "        del self.indices\n",
    "        del self.transform \n",
    "\n",
    "    def build_data(self , folder_path):\n",
    "        files = sorted(os.listdir(folder_path))\n",
    "        files = sorted(files)\n",
    "        data = []\n",
    "        print(\"Loading data!\")\n",
    "        for idx in tqdm(self.indices):\n",
    "            image_path = self.images_folder + f'/CLEVRTEX_full_{idx:06d}.png'\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            data.append(self.transform(image))\n",
    "            \n",
    "        print(\"Loaded data!\")\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.images_folder))\n",
    "    def __getitem__(self , idx):\n",
    "        return self.all_data[idx]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "  transforms.PILToTensor(),\n",
    "  transforms.ConvertImageDtype(torch.float),\n",
    "  transforms.Normalize((0.5 ,  0.5 , 0.5), (0.5, 0.5 , 0.5)),\n",
    "])\n",
    "\n",
    "\n",
    "val_data = ImageDatasetSlotAttention(images_folder = images_val,\n",
    "                                    indices = clever6_indices , transform = transform)\n",
    "print(\"image tensor max-min\" , val_data[0].max().item() , val_data[0].min().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc151396",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T10:23:29.175261Z",
     "iopub.status.busy": "2024-05-06T10:23:29.174463Z",
     "iopub.status.idle": "2024-05-06T10:23:29.188809Z",
     "shell.execute_reply": "2024-05-06T10:23:29.187938Z"
    },
    "papermill": {
     "duration": 0.043448,
     "end_time": "2024-05-06T10:23:29.190733",
     "exception": false,
     "start_time": "2024-05-06T10:23:29.147285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Block(Module):\n",
    "    def __init__(self, channels):\n",
    "        super(Block, self).__init__()\n",
    "        self.downsample = Sequential(OrderedDict([\n",
    "            ('conv1' , Conv2d(channels, channels, kernel_size = 5 , stride = 1 , padding = 2)),\n",
    "            ('bn1'   , BatchNorm2d(channels)),\n",
    "            ('relu1' , ReLU()),\n",
    "            ('conv2' , Conv2d(channels, channels, kernel_size = 5 , stride = 1 , padding = 2)),\n",
    "            ('bn2'   , BatchNorm2d(channels))\n",
    "        ]))\n",
    "        \n",
    "        self.relu = ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(x + self.downsample(x))\n",
    "\n",
    "class BlockUp(Module):\n",
    "    def __init__(self , in_channels , out_channels):\n",
    "        super(BlockUp, self).__init__()\n",
    "        \n",
    "        self.downsample = Sequential(OrderedDict([\n",
    "            ('conv1' , Conv2d(in_channels , out_channels , kernel_size = 5 , stride = 1 , padding = 2)),\n",
    "            ('bn1'   , BatchNorm2d(out_channels)),\n",
    "            ('relu1' , ReLU()),\n",
    "            ('conv2' , Conv2d(out_channels , out_channels , kernel_size = 5 , stride = 1 , padding = 2)),\n",
    "            ('bn2'   , BatchNorm2d(out_channels)),\n",
    "        ]))\n",
    "        self.skip = Sequential(OrderedDict([\n",
    "            ('conv1' , Conv2d(in_channels , out_channels, kernel_size = 5 , stride = 1 , padding = 2)),\n",
    "            ('bn1'   , BatchNorm2d(out_channels))\n",
    "        ]))\n",
    "        self.relu = ReLU()\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(self.skip(x) + self.downsample(x))\n",
    "    \n",
    "    \n",
    "class ResNet18(Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(ResNet18, self).__init__()\n",
    "        layer0 = Sequential(OrderedDict([\n",
    "         ('conv' , Conv2d(3 , 16 , kernel_size = 5 , stride = 1 , padding = 2)),\n",
    "         ('bn'   , BatchNorm2d(16)),\n",
    "         ('relu' , ReLU())\n",
    "        ]))\n",
    "\n",
    "        self.resnet = Sequential(OrderedDict([\n",
    "            ('layer0' , layer0),\n",
    "            ('block1' , Block(16)),\n",
    "            ('block2' , Block(16)),\n",
    "            ('block3' , BlockUp(16 , 32)),\n",
    "            ('block4' , Block(32)),\n",
    "            ('block5' , Block(32)),\n",
    "            ('block6' , BlockUp(32 , 64)),\n",
    "            ('block7' , Block(64)),\n",
    "            ('block8' , Block(64))\n",
    "        ]))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "464d8fdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T10:23:29.244457Z",
     "iopub.status.busy": "2024-05-06T10:23:29.244180Z",
     "iopub.status.idle": "2024-05-06T10:23:29.278990Z",
     "shell.execute_reply": "2024-05-06T10:23:29.278206Z"
    },
    "papermill": {
     "duration": 0.064386,
     "end_time": "2024-05-06T10:23:29.280914",
     "exception": false,
     "start_time": "2024-05-06T10:23:29.216528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ObjectDiscovery(Module):\n",
    "    def __init__(self , encoder_resolution ,  decoder_resolution , T   , K , D_slots):\n",
    "        super(ObjectDiscovery , self).__init__()\n",
    "        print(f'Initialized ObjectDiscovery!')\n",
    "        self.layers = Sequential(OrderedDict([\n",
    "          (\"encoder\" , ImageEncoder(resolution = encoder_resolution , T = T,\n",
    "                                    K = K , D_slots = D_slots )),\n",
    "          (\"decoder\" , SlotAttentionDecoder(resolution = decoder_resolution , K = K , D_slots = D_slots))\n",
    "        ]))\n",
    "    def forward(self , image):\n",
    "        return self.layers(image)\n",
    "\n",
    "class PositionEncoder(Module):\n",
    "    def __init__(self, output_dim , resolution):\n",
    "        super(PositionEncoder , self).__init__()\n",
    "        self.linear =  Linear(in_features = 4 , out_features = output_dim)\n",
    "        # above is equivalent to a linear layer\n",
    "        self.grid = Parameter(data = PositionEncoder.build_grid(resolution) , requires_grad = False)\n",
    "        print(\"Grid shape:\" , self.grid.shape)\n",
    "\n",
    "    @staticmethod\n",
    "    def build_grid(resolution):\n",
    "        ranges = [np.linspace(start = 0.0 , stop = 1.0 , num = dimension) for dimension in resolution] # dim = (2 , 128)\n",
    "        grid = np.meshgrid(*ranges , sparse = False, indexing = \"ij\") # dim = (128 , 128)\n",
    "        # row[i] of grid[0] has all elements i / 127 and col[j] of grid[1] has all elements j / 127\n",
    "        grid = np.stack(grid , axis = -1) # dim = (64 , 64 , 2) to match conv later\n",
    "        grid = np.expand_dims(grid, axis = 0) # dim = (1 , 64 , 64 , 2) for batch dimension\n",
    "        grid = grid.astype(np.float32) # PyTorch throws an error later otherwise\n",
    "        return torch.tensor(np.concatenate([grid , 1.0 - grid] , axis = 3)) # (1 , 64 , 64 , 4)\n",
    "\n",
    "\n",
    "    def forward(self, x): # x has shape (batch , 64 , 64 , D_inputs)\n",
    "        return x + self.linear(self.grid)\n",
    "\n",
    "\n",
    "class ImageEncoder(Module):\n",
    "    def __init__(self , resolution , T  ,  K , D_slots):\n",
    "        super(ImageEncoder , self).__init__()\n",
    "        print(f'Initialized ImageEncoder! resolution: {resolution}')\n",
    "        D_inputs = 64\n",
    "        self.encoder_cnn = ResNet18()\n",
    "        down_resolution = (128 , 128)\n",
    "        positional_encoder = PositionEncoder(output_dim =  D_inputs , resolution = down_resolution)\n",
    "\n",
    "\n",
    "        slot_attention = SlotAttention(T = T , K = K , D_slots = D_slots)\n",
    "        self.pos_encode_feedforward_slotattn = Sequential(OrderedDict([\n",
    "            (\"pos_encoder\" , positional_encoder), #  (batch , 64 , 64 , D_inputs)\n",
    "            (\"flatten\" , Flatten(start_dim = 1 , end_dim = 2)), # (batch , 64 * 64 , D_inputs)\n",
    "            (\"layer_norm\" ,  LayerNorm(normalized_shape = 64)), # (batch , 64 * 64 , D_inputs)\n",
    "            (\"linear1:\" , Linear(in_features = 64 , out_features = 128)),\n",
    "            (\"relu1:\"   , ReLU()),\n",
    "            (\"linear2:\" , Linear(in_features = 128 , out_features = 128)),\n",
    "            (\"slot_attention\" , slot_attention) #  (batch , K , D_slots)\n",
    "        ]))\n",
    "    # feature map has shape (channels , h , w)\n",
    "    # N is h * w i.e. each pixel is a different feature \"vector\", size of this vector of D_inputs = # of channels\n",
    "    # channels = D_inputs , h * w = N\n",
    "    def forward(self , x): # x is aimge with shape (batch , 3 , 126 , 128)\n",
    "        x = self.encoder_cnn(x).permute(dims = (0 , 2 , 3 , 1))  # (batch , 64 , 64 , D_inputs)\n",
    "        return self.pos_encode_feedforward_slotattn(x)\n",
    "\n",
    "\n",
    "\n",
    "class SlotAttention(Module):\n",
    "    def __init__(self , T, K , D_slots  , epsilon = 1e-8):\n",
    "        super(SlotAttention , self).__init__()\n",
    "        print(f'Initialzing SlotAttention parameters: T: {T} , K: {K} , D_slots: {D_slots}')\n",
    "        self.T = T\n",
    "        self.K = K\n",
    "        self.D_slots = D_slots\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        self.norm_inputs = LayerNorm(normalized_shape =  128)\n",
    "        self.query_from_slots  = Sequential(OrderedDict([\n",
    "            (\"NormSlots\" , LayerNorm(normalized_shape = D_slots)),\n",
    "            (\"SlotQuery\" , Linear(in_features = D_slots  , out_features = D_slots , bias = False))\n",
    "        ]))\n",
    "\n",
    "\n",
    "#         self.slots_init = Parameter(data = normal_(torch.empty(1 , K , D_slots)) , requires_grad = True)\n",
    "\n",
    "        self.init_latents = Parameter(normal_(torch.empty(1 , self.K , self.D_slots)))\n",
    "\n",
    "\n",
    "\n",
    "        self.keys_from_inputs  = Linear(in_features = 128 , out_features = D_slots , bias = False)\n",
    "        self.vals_from_inputs  = Linear(in_features = 128 , out_features = D_slots , bias = False)\n",
    "        self.gru = GRUCell(input_size = D_slots , hidden_size = D_slots)\n",
    "        self.norm_feed = Sequential(OrderedDict([\n",
    "            (\"layer_norm\" ,  LayerNorm(normalized_shape = D_slots)),\n",
    "            (\"linear1\" , Linear(in_features = D_slots , out_features = 256)),\n",
    "            (\"relu1\"   , ReLU()),\n",
    "            (\"linear2\" , Linear(in_features = 256 , out_features = D_slots))\n",
    "        ]))\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.shape[0]\n",
    "        inputs = self.norm_inputs(inputs)\n",
    "        keys = self.keys_from_inputs(inputs)\n",
    "        vals = self.vals_from_inputs(inputs)\n",
    "        slots = self.init_latents.repeat(batch_size , 1 , 1)\n",
    "        for _ in range(self.T):\n",
    "            slots_prev = slots\n",
    "            queries = self.query_from_slots(slots)\n",
    "            attn_logits = (self.D_slots ** -0.5) * torch.einsum('bnc,bmc->bnm', keys , queries)\n",
    "            attn = F.softmax(attn_logits , dim = -1)\n",
    "            attn = attn + self.epsilon\n",
    "            attn = attn / torch.sum(attn, dim = 1, keepdim = True)\n",
    "            updates = torch.einsum('bnm,bnc->bmc' , attn , vals)\n",
    "            slots = self.gru(\n",
    "                updates.view(batch_size * self.K , self.D_slots),\n",
    "                slots_prev.view(batch_size * self.K , self.D_slots),\n",
    "            )\n",
    "            slots = slots.view(batch_size , self.K , self.D_slots)\n",
    "            slots = slots + self.norm_feed(slots)\n",
    "\n",
    "        return slots\n",
    "\n",
    "\n",
    "class SlotAttentionDecoder(Module):\n",
    "    def __init__(self , resolution , K , D_slots):\n",
    "        super(SlotAttentionDecoder , self).__init__()\n",
    "        print(f'Initialized SlotAttentionDecoder! resolution: {resolution}')\n",
    "        print(f'Decoder parameters: K: {K} , D_slots: {D_slots}')\n",
    "        self.resolution = resolution\n",
    "        self.positional_encoder = PositionEncoder(output_dim = D_slots , resolution = resolution)\n",
    "\n",
    "        self.K = K\n",
    "        self.D_slots = D_slots\n",
    "\n",
    "        self.decoder_cnn = Sequential(OrderedDict([\n",
    "            (\"conv1\" , ConvTranspose2d(in_channels = D_slots , out_channels = 64 , kernel_size = 5 , stride = 2 , padding = 2 , output_padding = 1)),\n",
    "            ('relu1' , ReLU()),\n",
    "            (\"conv2\" , ConvTranspose2d(in_channels = 64 , out_channels = 64 , kernel_size = 5 , stride = 2 , padding = 2 , output_padding = 1)),\n",
    "            ('relu2' , ReLU()),\n",
    "            (\"conv3\" , ConvTranspose2d(in_channels = 64 , out_channels = 64 , kernel_size = 5 , stride = 2 , padding = 2 , output_padding = 1)),\n",
    "            ('relu3' , ReLU()),\n",
    "            (\"conv4\" , ConvTranspose2d(in_channels = 64 , out_channels = 64 , kernel_size = 5 , stride = 2 , padding = 2 , output_padding = 1)),\n",
    "            ('relu4' , ReLU()),\n",
    "            (\"conv5\" , ConvTranspose2d(in_channels = 64 , out_channels = 4 , kernel_size = 1 , stride = 1)),\n",
    "        ]))\n",
    "\n",
    "\n",
    "    def forward(self , slots):\n",
    "        # slots comes form the ImageEncoder shape : (batch , K , D_slots)\n",
    "        batch_size = slots.shape[0]\n",
    "        x =  slots.view(batch_size * self.K , 1 , 1 , self.D_slots)\n",
    "        x = x.repeat(1 , self.resolution[0] , self.resolution[1] , 1)\n",
    "        x = self.positional_encoder(x).permute(0 , 3 , 1 , 2)\n",
    "        x = self.decoder_cnn(x) # dim = (batch * K , 4 , 128 , 128)\n",
    "        x = x.view(batch_size, self.K , 4 , 128 , 128)# dim = (batch , K , 4 , 128 , 128)\n",
    "        recons , masks = x[: , : , : 3 , : , :]  , x[: , : , -1 : , : , :]\n",
    "        masks = F.softmax(masks , dim = 1) # dim = (batch , K , 1 , 128, 128)\n",
    "        reconstructed = torch.sum(recons * masks , dim = 1) # dim = (batch , 3 , 128, 128)\n",
    "        return reconstructed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4274667",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T10:23:29.334864Z",
     "iopub.status.busy": "2024-05-06T10:23:29.334607Z",
     "iopub.status.idle": "2024-05-06T10:23:29.422602Z",
     "shell.execute_reply": "2024-05-06T10:23:29.421558Z"
    },
    "papermill": {
     "duration": 0.118258,
     "end_time": "2024-05-06T10:23:29.424533",
     "exception": false,
     "start_time": "2024-05-06T10:23:29.306275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: torch.Size([3, 128, 128])\n",
      "val data size  : 5319\n",
      "# val batches  : 84\n",
      "mini-batch size  : 64\n",
      "num_workers val: 1\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def show_gpus():\n",
    "    if torch.cuda.is_available():\n",
    "        num_gpus = torch.cuda.device_count()\n",
    "        print(\"Number of available GPUs:\", num_gpus)\n",
    "\n",
    "\n",
    "        for i in range(num_gpus):\n",
    "            gpu_properties = torch.cuda.get_device_properties(i)\n",
    "            print(f\"GPU {i}: {gpu_properties.name}, Memory: {gpu_properties.total_memory / 1024**3:.2f}GB\")\n",
    "    else:\n",
    "        print(\"CUDA is not available. Running on CPU.\")\n",
    "\n",
    "def get_loss(model_ , data_loader):\n",
    "    model_.eval()\n",
    "    loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images in data_loader:\n",
    "            images = images.to(device)\n",
    "            reconst = model_(images)\n",
    "            loss += criterion(reconst , images).item()\n",
    "\n",
    "    return loss / len(data_loader)\n",
    "BATCH_SIZE = 64\n",
    "val_loader = DataLoader(val_data , batch_size = BATCH_SIZE , shuffle = True , num_workers = 1 , pin_memory = True)\n",
    "print(\"image shape:\" , val_data[0].shape)\n",
    "print(\"val data size  :\" , len(val_data))\n",
    "print(\"# val batches  :\" , len(val_loader))\n",
    "print(\"mini-batch size  :\" , BATCH_SIZE)\n",
    "print(\"num_workers val:\" , val_loader.num_workers)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\" , device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2714c33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-06T10:23:29.477075Z",
     "iopub.status.busy": "2024-05-06T10:23:29.476401Z",
     "iopub.status.idle": "2024-05-06T12:19:00.666944Z",
     "shell.execute_reply": "2024-05-06T12:19:00.665773Z"
    },
    "papermill": {
     "duration": 6931.248998,
     "end_time": "2024-05-06T12:19:00.698778",
     "exception": false,
     "start_time": "2024-05-06T10:23:29.449780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized ObjectDiscovery!\n",
      "Initialized ImageEncoder! resolution: (128, 128)\n",
      "Grid shape: torch.Size([1, 128, 128, 4])\n",
      "Initialzing SlotAttention parameters: T: 3 , K: 7 , D_slots: 128\n",
      "Initialized SlotAttentionDecoder! resolution: (8, 8)\n",
      "Decoder parameters: K: 7 , D_slots: 128\n",
      "Grid shape: torch.Size([1, 8, 8, 4])\n",
      "Saved!\n"
     ]
    }
   ],
   "source": [
    "val_losses = []\n",
    "criterion = MSELoss()\n",
    "model = DataParallel(ObjectDiscovery(encoder_resolution = (128 , 128) , decoder_resolution = (8 , 8),\n",
    "                    T = 3 ,  K = 7 , D_slots = 128))\n",
    "for epoch in range(1 , 181):\n",
    "    model_path = f'/kaggle/input/v17-checkpoints/checkpoints/model_{epoch}'\n",
    "    model_dict = torch.load(model_path)\n",
    "    model.load_state_dict(model_dict['model_state_dict'])\n",
    "    model.to(device)\n",
    "    val_losses.append(get_loss(model , val_loader))\n",
    "\n",
    "\n",
    "\n",
    "val_losses = np.array(val_losses)\n",
    "np.save('val_loss_save.npy' , val_losses)\n",
    "print(\"Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afd643c",
   "metadata": {
    "papermill": {
     "duration": 0.02705,
     "end_time": "2024-05-06T12:19:00.754223",
     "exception": false,
     "start_time": "2024-05-06T12:19:00.727173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4942474,
     "sourceId": 8320688,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4949343,
     "sourceId": 8334264,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6972.603752,
   "end_time": "2024-05-06T12:19:02.417016",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-06T10:22:49.813264",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
