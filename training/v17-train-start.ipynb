{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4931355",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-05T05:52:02.432842Z",
     "iopub.status.busy": "2024-05-05T05:52:02.432192Z",
     "iopub.status.idle": "2024-05-05T05:52:09.849687Z",
     "shell.execute_reply": "2024-05-05T05:52:09.848574Z"
    },
    "papermill": {
     "duration": 7.424298,
     "end_time": "2024-05-05T05:52:09.851754",
     "exception": false,
     "start_time": "2024-05-05T05:52:02.427456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's Go!\n",
      "torch version: 2.1.2\n"
     ]
    }
   ],
   "source": [
    "print(\"Let's Go!\" )\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from torch.optim import Adam\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import LayerNorm\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.init import xavier_uniform_\n",
    "from torch.nn import BatchNorm2d\n",
    "from torch.nn import Parameter\n",
    "from torch.nn import Linear\n",
    "from torch.nn import DataParallel\n",
    "from torch.nn import Sequential\n",
    "from torch.nn import ConvTranspose2d\n",
    "from torch.nn import GRUCell\n",
    "from torch.nn import Module\n",
    "from torch.nn import Flatten\n",
    "from torch.nn.init import normal_\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.functional import softmax\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Conv1d\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import MSELoss\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "print(\"torch version:\" , torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58231890",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T05:52:09.860097Z",
     "iopub.status.busy": "2024-05-05T05:52:09.859678Z",
     "iopub.status.idle": "2024-05-05T05:54:01.178559Z",
     "shell.execute_reply": "2024-05-05T05:54:01.177633Z"
    },
    "papermill": {
     "duration": 111.32511,
     "end_time": "2024-05-05T05:54:01.180675",
     "exception": false,
     "start_time": "2024-05-05T05:52:09.855565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21361/21361 [01:49<00:00, 195.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data!\n",
      "data size: (21361, 3, 128, 128)\n",
      "tensor max-min 0.9686274528503418 -0.8666666746139526\n"
     ]
    }
   ],
   "source": [
    "images_train = '/kaggle/input/clevertex6-train-images/CLEVERTex6_train_images'\n",
    "CROP_SIZE  = (192 , 192)\n",
    "ENCODER_RESOLUTION = (128 , 128)\n",
    "DECODER_RESOLUTION = (8 , 8)\n",
    "\n",
    "class ImageDatasetSlotAttention(Dataset):\n",
    "    def __init__(self, images_folder , transform):\n",
    "        super(ImageDatasetSlotAttention , self).__init__()\n",
    "        self.images_folder = images_folder\n",
    "        self.folder = images_folder\n",
    "        self.transform = transform\n",
    "        self.all_data =  self.build_data(images_folder)\n",
    "        print(\"data size:\" , self.all_data.shape)\n",
    "\n",
    "\n",
    "    def build_data(self , folder_path):\n",
    "        files = os.listdir(folder_path)\n",
    "        files = sorted(files)\n",
    "        data = []\n",
    "        print(\"Loading data!\")\n",
    "        for file in tqdm(files):\n",
    "            image = Image.open(f'{self.folder}/{file}').convert('RGB')\n",
    "            data.append(self.transform(image))\n",
    "        print(\"Loaded data!\")\n",
    "        return np.array(data)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.images_folder))\n",
    "    def __getitem__(self , idx):\n",
    "        return self.all_data[idx]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "  transforms.PILToTensor(),\n",
    "  transforms.ConvertImageDtype(torch.float),\n",
    "  transforms.Normalize((0.5 ,  0.5 , 0.5), (0.5, 0.5 , 0.5)),\n",
    "])\n",
    "\n",
    "train_data = ImageDatasetSlotAttention(images_folder = images_train , transform = transform)\n",
    "print(\"tensor max-min\" , train_data[0].max().item() , train_data[0].min().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e0b77db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T05:54:01.352222Z",
     "iopub.status.busy": "2024-05-05T05:54:01.351700Z",
     "iopub.status.idle": "2024-05-05T05:54:01.366853Z",
     "shell.execute_reply": "2024-05-05T05:54:01.365994Z"
    },
    "papermill": {
     "duration": 0.102936,
     "end_time": "2024-05-05T05:54:01.368943",
     "exception": false,
     "start_time": "2024-05-05T05:54:01.266007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# At training time, we use T = 3 iterations of Slot Attention.\n",
    "# number of slots K: we use K = 7 slots for\n",
    "# N for us is 128 and D_inputs = 64 which is the final number of feature maps\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Block(Module):\n",
    "    def __init__(self, channels):\n",
    "        super(Block, self).__init__()\n",
    "        self.downsample = Sequential(OrderedDict([\n",
    "            ('conv1' , Conv2d(channels, channels, kernel_size = 5 , stride = 1 , padding = 2)),\n",
    "            ('bn1'   , BatchNorm2d(channels)),\n",
    "            ('relu1' , ReLU()),\n",
    "            ('conv2' , Conv2d(channels, channels, kernel_size = 5 , stride = 1 , padding = 2)),\n",
    "            ('bn2'   , BatchNorm2d(channels))\n",
    "        ]))\n",
    "        \n",
    "        self.relu = ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(x + self.downsample(x))\n",
    "\n",
    "class BlockUp(Module):\n",
    "    def __init__(self , in_channels , out_channels):\n",
    "        super(BlockUp, self).__init__()\n",
    "        \n",
    "        self.downsample = Sequential(OrderedDict([\n",
    "            ('conv1' , Conv2d(in_channels , out_channels , kernel_size = 5 , stride = 1 , padding = 2)),\n",
    "            ('bn1'   , BatchNorm2d(out_channels)),\n",
    "            ('relu1' , ReLU()),\n",
    "            ('conv2' , Conv2d(out_channels , out_channels , kernel_size = 5 , stride = 1 , padding = 2)),\n",
    "            ('bn2'   , BatchNorm2d(out_channels)),\n",
    "        ]))\n",
    "        self.skip = Sequential(OrderedDict([\n",
    "            ('conv1' , Conv2d(in_channels , out_channels, kernel_size = 5 , stride = 1 , padding = 2)),\n",
    "            ('bn1'   , BatchNorm2d(out_channels))\n",
    "        ]))\n",
    "        self.relu = ReLU()\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(self.skip(x) + self.downsample(x))\n",
    "    \n",
    "    \n",
    "class ResNet18(Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(ResNet18, self).__init__()\n",
    "#         layer1 = self.__make_layer(64, 64)\n",
    "#         layer2 = self.__make_layer(64, 64)\n",
    "#         layer3 = self.__make_layer(64, 64)\n",
    "#         layer4 = self.__make_layer(64, 64)\n",
    "    \n",
    "        layer0 = Sequential(OrderedDict([\n",
    "         ('conv' , Conv2d(3 , 16 , kernel_size = 5 , stride = 1 , padding = 2)),\n",
    "         ('bn'   , BatchNorm2d(16)),\n",
    "         ('relu' , ReLU())\n",
    "        ]))\n",
    "\n",
    "        self.resnet = Sequential(OrderedDict([\n",
    "            ('layer0' , layer0),\n",
    "            ('block1' , Block(16)),\n",
    "            ('block2' , Block(16)),\n",
    "            ('block3' , BlockUp(16 , 32)),\n",
    "            ('block4' , Block(32)),\n",
    "            ('block5' , Block(32)),\n",
    "            ('block6' , BlockUp(32 , 64)),\n",
    "            ('block7' , Block(64)),\n",
    "            ('block8' , Block(64))\n",
    "        ]))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.resnet(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6686303f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T05:54:01.542636Z",
     "iopub.status.busy": "2024-05-05T05:54:01.542203Z",
     "iopub.status.idle": "2024-05-05T05:54:01.576999Z",
     "shell.execute_reply": "2024-05-05T05:54:01.576106Z"
    },
    "papermill": {
     "duration": 0.12263,
     "end_time": "2024-05-05T05:54:01.579008",
     "exception": false,
     "start_time": "2024-05-05T05:54:01.456378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ObjectDiscovery(Module):\n",
    "    def __init__(self , encoder_resolution ,  decoder_resolution , T   , K , D_slots):\n",
    "        super(ObjectDiscovery , self).__init__()\n",
    "        print(f'Initialized ObjectDiscovery!')\n",
    "        self.layers = Sequential(OrderedDict([\n",
    "          (\"encoder\" , ImageEncoder(resolution = encoder_resolution , T = T,\n",
    "                                    K = K , D_slots = D_slots )),\n",
    "          (\"decoder\" , SlotAttentionDecoder(resolution = decoder_resolution , K = K , D_slots = D_slots))\n",
    "        ]))\n",
    "    def forward(self , image):\n",
    "        return self.layers(image)\n",
    "\n",
    "class PositionEncoder(Module):\n",
    "    def __init__(self, output_dim , resolution):\n",
    "        super(PositionEncoder , self).__init__()\n",
    "        self.linear =  Linear(in_features = 4 , out_features = output_dim)\n",
    "        # above is equivalent to a linear layer\n",
    "        self.grid = Parameter(data = PositionEncoder.build_grid(resolution) , requires_grad = False)\n",
    "        print(\"Grid shape:\" , self.grid.shape)\n",
    "\n",
    "    @staticmethod\n",
    "    def build_grid(resolution):\n",
    "        ranges = [np.linspace(start = 0.0 , stop = 1.0 , num = dimension) for dimension in resolution] # dim = (2 , 128)\n",
    "        grid = np.meshgrid(*ranges , sparse = False, indexing = \"ij\") # dim = (128 , 128)\n",
    "        # row[i] of grid[0] has all elements i / 127 and col[j] of grid[1] has all elements j / 127\n",
    "        grid = np.stack(grid , axis = -1) # dim = (64 , 64 , 2) to match conv later\n",
    "        grid = np.expand_dims(grid, axis = 0) # dim = (1 , 64 , 64 , 2) for batch dimension\n",
    "        grid = grid.astype(np.float32) # PyTorch throws an error later otherwise\n",
    "        return torch.tensor(np.concatenate([grid , 1.0 - grid] , axis = 3)) # (1 , 64 , 64 , 4)\n",
    "\n",
    "\n",
    "    def forward(self, x): # x has shape (batch , 64 , 64 , D_inputs)\n",
    "        return x + self.linear(self.grid)\n",
    "\n",
    "\n",
    "class ImageEncoder(Module):\n",
    "    def __init__(self , resolution , T  ,  K , D_slots):\n",
    "        super(ImageEncoder , self).__init__()\n",
    "        print(f'Initialized ImageEncoder! resolution: {resolution}')\n",
    "        D_inputs = 64\n",
    "        self.encoder_cnn = ResNet18()\n",
    "        down_resolution = (128 , 128)\n",
    "        positional_encoder = PositionEncoder(output_dim =  D_inputs , resolution = down_resolution)\n",
    "\n",
    "\n",
    "        slot_attention = SlotAttention(T = T , K = K , D_slots = D_slots)\n",
    "        self.pos_encode_feedforward_slotattn = Sequential(OrderedDict([\n",
    "            (\"pos_encoder\" , positional_encoder), #  (batch , 64 , 64 , D_inputs)\n",
    "            (\"flatten\" , Flatten(start_dim = 1 , end_dim = 2)), # (batch , 64 * 64 , D_inputs)\n",
    "            (\"layer_norm\" ,  LayerNorm(normalized_shape = 64)), # (batch , 64 * 64 , D_inputs)\n",
    "            (\"linear1:\" , Linear(in_features = 64 , out_features = 128)),\n",
    "            (\"relu1:\"   , ReLU()),\n",
    "            (\"linear2:\" , Linear(in_features = 128 , out_features = 128)),\n",
    "            (\"slot_attention\" , slot_attention) #  (batch , K , D_slots)\n",
    "        ]))\n",
    "    # feature map has shape (channels , h , w)\n",
    "    # N is h * w i.e. each pixel is a different feature \"vector\", size of this vector of D_inputs = # of channels\n",
    "    # channels = D_inputs , h * w = N\n",
    "    def forward(self , x): # x is aimge with shape (batch , 3 , 126 , 128)\n",
    "        x = self.encoder_cnn(x).permute(dims = (0 , 2 , 3 , 1))  # (batch , 64 , 64 , D_inputs)\n",
    "        return self.pos_encode_feedforward_slotattn(x)\n",
    "\n",
    "\n",
    "\n",
    "class SlotAttention(Module):\n",
    "    def __init__(self , T, K , D_slots  , epsilon = 1e-8):\n",
    "        super(SlotAttention , self).__init__()\n",
    "        print(f'Initialzing SlotAttention parameters: T: {T} , K: {K} , D_slots: {D_slots}')\n",
    "        self.T = T\n",
    "        self.K = K\n",
    "        self.D_slots = D_slots\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "        self.norm_inputs = LayerNorm(normalized_shape =  128)\n",
    "        self.query_from_slots  = Sequential(OrderedDict([\n",
    "            (\"NormSlots\" , LayerNorm(normalized_shape = D_slots)),\n",
    "            (\"SlotQuery\" , Linear(in_features = D_slots  , out_features = D_slots , bias = False))\n",
    "        ]))\n",
    "\n",
    "\n",
    "#         self.slots_init = Parameter(data = normal_(torch.empty(1 , K , D_slots)) , requires_grad = True)\n",
    "\n",
    "        self.init_latents = Parameter(normal_(torch.empty(1 , self.K , self.D_slots)))\n",
    "\n",
    "\n",
    "\n",
    "        self.keys_from_inputs  = Linear(in_features = 128 , out_features = D_slots , bias = False)\n",
    "        self.vals_from_inputs  = Linear(in_features = 128 , out_features = D_slots , bias = False)\n",
    "        self.gru = GRUCell(input_size = D_slots , hidden_size = D_slots)\n",
    "        self.norm_feed = Sequential(OrderedDict([\n",
    "            (\"layer_norm\" ,  LayerNorm(normalized_shape = D_slots)),\n",
    "            (\"linear1\" , Linear(in_features = D_slots , out_features = 256)),\n",
    "            (\"relu1\"   , ReLU()),\n",
    "            (\"linear2\" , Linear(in_features = 256 , out_features = D_slots))\n",
    "        ]))\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        batch_size = inputs.shape[0]\n",
    "        inputs = self.norm_inputs(inputs)\n",
    "        keys = self.keys_from_inputs(inputs)\n",
    "        vals = self.vals_from_inputs(inputs)\n",
    "        slots = self.init_latents.repeat(batch_size , 1 , 1)\n",
    "        for _ in range(self.T):\n",
    "            slots_prev = slots\n",
    "            queries = self.query_from_slots(slots)\n",
    "            attn_logits = (self.D_slots ** -0.5) * torch.einsum('bnc,bmc->bnm', keys , queries)\n",
    "            attn = F.softmax(attn_logits , dim = -1)\n",
    "            attn = attn + self.epsilon\n",
    "            attn = attn / torch.sum(attn, dim = 1, keepdim = True)\n",
    "            updates = torch.einsum('bnm,bnc->bmc' , attn , vals)\n",
    "            slots = self.gru(\n",
    "                updates.view(batch_size * self.K , self.D_slots),\n",
    "                slots_prev.view(batch_size * self.K , self.D_slots),\n",
    "            )\n",
    "            slots = slots.view(batch_size , self.K , self.D_slots)\n",
    "            slots = slots + self.norm_feed(slots)\n",
    "\n",
    "        return slots\n",
    "\n",
    "\n",
    "class SlotAttentionDecoder(Module):\n",
    "    def __init__(self , resolution , K , D_slots):\n",
    "        super(SlotAttentionDecoder , self).__init__()\n",
    "        print(f'Initialized SlotAttentionDecoder! resolution: {resolution}')\n",
    "        print(f'Decoder parameters: K: {K} , D_slots: {D_slots}')\n",
    "        self.resolution = resolution\n",
    "        self.positional_encoder = PositionEncoder(output_dim = D_slots , resolution = resolution)\n",
    "\n",
    "        self.K = K\n",
    "        self.D_slots = D_slots\n",
    "\n",
    "        self.decoder_cnn = Sequential(OrderedDict([\n",
    "            (\"conv1\" , ConvTranspose2d(in_channels = D_slots , out_channels = 64 , kernel_size = 5 , stride = 2 , padding = 2 , output_padding = 1)),\n",
    "            ('relu1' , ReLU()),\n",
    "            (\"conv2\" , ConvTranspose2d(in_channels = 64 , out_channels = 64 , kernel_size = 5 , stride = 2 , padding = 2 , output_padding = 1)),\n",
    "            ('relu2' , ReLU()),\n",
    "            (\"conv3\" , ConvTranspose2d(in_channels = 64 , out_channels = 64 , kernel_size = 5 , stride = 2 , padding = 2 , output_padding = 1)),\n",
    "            ('relu3' , ReLU()),\n",
    "            (\"conv4\" , ConvTranspose2d(in_channels = 64 , out_channels = 64 , kernel_size = 5 , stride = 2 , padding = 2 , output_padding = 1)),\n",
    "            ('relu4' , ReLU()),\n",
    "            (\"conv5\" , ConvTranspose2d(in_channels = 64 , out_channels = 4 , kernel_size = 1 , stride = 1)),\n",
    "        ]))\n",
    "\n",
    "\n",
    "    def forward(self , slots):\n",
    "        # slots comes form the ImageEncoder shape : (batch , K , D_slots)\n",
    "        batch_size = slots.shape[0]\n",
    "        x =  slots.view(batch_size * self.K , 1 , 1 , self.D_slots)\n",
    "        x = x.repeat(1 , self.resolution[0] , self.resolution[1] , 1)\n",
    "        x = self.positional_encoder(x).permute(0 , 3 , 1 , 2)\n",
    "        x = self.decoder_cnn(x) # dim = (batch * K , 4 , 128 , 128)\n",
    "        x = x.view(batch_size, self.K , 4 , 128 , 128)# dim = (batch , K , 4 , 128 , 128)\n",
    "        recons , masks = x[: , : , : 3 , : , :]  , x[: , : , -1 : , : , :]\n",
    "        masks = F.softmax(masks , dim = 1) # dim = (batch , K , 1 , 128, 128)\n",
    "        reconstructed = torch.sum(recons * masks , dim = 1) # dim = (batch , 3 , 128, 128)\n",
    "        return reconstructed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dd5b9a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T05:54:01.791015Z",
     "iopub.status.busy": "2024-05-05T05:54:01.790618Z",
     "iopub.status.idle": "2024-05-05T05:54:01.907100Z",
     "shell.execute_reply": "2024-05-05T05:54:01.905918Z"
    },
    "papermill": {
     "duration": 0.244758,
     "end_time": "2024-05-05T05:54:01.909239",
     "exception": false,
     "start_time": "2024-05-05T05:54:01.664481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: (3, 128, 128)\n",
      "train data size  : 21361\n",
      "# train batches  : 334\n",
      "mini-batch size  : 64\n",
      "num_workers train: 1\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(train_data , batch_size = BATCH_SIZE , shuffle = True , num_workers = 1 , pin_memory = True)\n",
    "print(\"image shape:\" , train_data[0].shape)\n",
    "print(\"train data size  :\" , len(train_data))\n",
    "print(\"# train batches  :\" , len(train_loader))\n",
    "print(\"mini-batch size  :\" , BATCH_SIZE)\n",
    "print(\"num_workers train:\" , train_loader.num_workers)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\" , device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5ea65a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T05:54:02.084083Z",
     "iopub.status.busy": "2024-05-05T05:54:02.083732Z",
     "iopub.status.idle": "2024-05-05T05:54:02.093365Z",
     "shell.execute_reply": "2024-05-05T05:54:02.092432Z"
    },
    "papermill": {
     "duration": 0.100434,
     "end_time": "2024-05-05T05:54:02.095479",
     "exception": false,
     "start_time": "2024-05-05T05:54:01.995045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_directory(directory_path):\n",
    "    if os.path.exists(directory_path):\n",
    "        shutil.rmtree(directory_path)\n",
    "        print(f\"Directory '{directory_path}' deleted.\")\n",
    "\n",
    "    os.makedirs(directory_path)\n",
    "    print(f\"Directory '{directory_path}' created successfully.\")\n",
    "\n",
    "def save_model(epoch , model , optimizer , train_loss , path):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_loss': train_loss,\n",
    "        }, path)\n",
    "\n",
    "\n",
    "def show_gpus():\n",
    "    if torch.cuda.is_available():\n",
    "        num_gpus = torch.cuda.device_count()\n",
    "        print(\"Number of available GPUs:\", num_gpus)\n",
    "\n",
    "\n",
    "        for i in range(num_gpus):\n",
    "            gpu_properties = torch.cuda.get_device_properties(i)\n",
    "            print(f\"GPU {i}: {gpu_properties.name}, Memory: {gpu_properties.total_memory / 1024**3:.2f}GB\")\n",
    "    else:\n",
    "        print(\"CUDA is not available. Running on CPU.\")\n",
    "\n",
    "def get_loss(model_ , data_loader):\n",
    "    model_.eval()\n",
    "    loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images in data_loader:\n",
    "            images = images.to(device)\n",
    "            reconst = model_(images)\n",
    "            loss += criterion(reconst , images).item()\n",
    "    return loss / len(data_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb8143ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T05:54:02.265629Z",
     "iopub.status.busy": "2024-05-05T05:54:02.265336Z",
     "iopub.status.idle": "2024-05-05T15:10:39.404096Z",
     "shell.execute_reply": "2024-05-05T15:10:39.403112Z"
    },
    "papermill": {
     "duration": 33397.315413,
     "end_time": "2024-05-05T15:10:39.496310",
     "exception": false,
     "start_time": "2024-05-05T05:54:02.180897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'results' created successfully.\n",
      "Number of available GPUs: 2\n",
      "GPU 0: Tesla T4, Memory: 14.75GB\n",
      "GPU 1: Tesla T4, Memory: 14.75GB\n",
      "Initialized ObjectDiscovery!\n",
      "Initialized ImageEncoder! resolution: (128, 128)\n",
      "Grid shape: torch.Size([1, 128, 128, 4])\n",
      "Initialzing SlotAttention parameters: T: 3 , K: 7 , D_slots: 128\n",
      "Initialized SlotAttentionDecoder! resolution: (8, 8)\n",
      "Decoder parameters: K: 7 , D_slots: 128\n",
      "Grid shape: torch.Size([1, 8, 8, 4])\n",
      "epoch     : 1\n",
      "train loss: 0.12863549594572204\n",
      "learning rate: 0.0009999036202410325\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 2\n",
      "train loss: 0.09812912012556356\n",
      "learning rate: 0.0009996145181203615\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 3\n",
      "train loss: 0.09245876662299304\n",
      "learning rate: 0.000999132805092358\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 4\n",
      "train loss: 0.0897784554092827\n",
      "learning rate: 0.0009984586668665642\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 5\n",
      "train loss: 0.08505969378584159\n",
      "learning rate: 0.0009975923633360987\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 6\n",
      "train loss: 0.07840189627723065\n",
      "learning rate: 0.0009965342284774634\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 7\n",
      "train loss: 0.06810095412154754\n",
      "learning rate: 0.0009952846702217888\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 8\n",
      "train loss: 0.06052306940232565\n",
      "learning rate: 0.000993844170297569\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 9\n",
      "train loss: 0.05672189357974929\n",
      "learning rate: 0.000992213284044946\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 10\n",
      "train loss: 0.053960720188692655\n",
      "learning rate: 0.0009903926402016153\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 11\n",
      "train loss: 0.05182217517700381\n",
      "learning rate: 0.0009883829406604364\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 12\n",
      "train loss: 0.04997720270456668\n",
      "learning rate: 0.0009861849601988384\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 13\n",
      "train loss: 0.04858736759665126\n",
      "learning rate: 0.00098379954618013\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 14\n",
      "train loss: 0.047328494979949766\n",
      "learning rate: 0.0009812276182268238\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 15\n",
      "train loss: 0.04592563027884075\n",
      "learning rate: 0.0009784701678661046\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 16\n",
      "train loss: 0.0446897982257212\n",
      "learning rate: 0.0009755282581475771\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 17\n",
      "train loss: 0.043346060484558524\n",
      "learning rate: 0.0009724030232334394\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 18\n",
      "train loss: 0.04205717869147569\n",
      "learning rate: 0.0009690956679612424\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 19\n",
      "train loss: 0.04142390789386041\n",
      "learning rate: 0.000965607467379402\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 20\n",
      "train loss: 0.040946492010694065\n",
      "learning rate: 0.0009619397662556437\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 21\n",
      "train loss: 0.04012254580944598\n",
      "learning rate: 0.0009580939785585683\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 22\n",
      "train loss: 0.03909036255034501\n",
      "learning rate: 0.0009540715869125409\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 23\n",
      "train loss: 0.03859227499227502\n",
      "learning rate: 0.000949874142026111\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 24\n",
      "train loss: 0.03776069177861164\n",
      "learning rate: 0.0009455032620941842\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 25\n",
      "train loss: 0.03730877335490045\n",
      "learning rate: 0.0009409606321741778\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 26\n",
      "train loss: 0.036802102973361214\n",
      "learning rate: 0.0009362480035363989\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 27\n",
      "train loss: 0.035769220737149256\n",
      "learning rate: 0.0009313671929888962\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 28\n",
      "train loss: 0.03548691425650955\n",
      "learning rate: 0.0009263200821770464\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 29\n",
      "train loss: 0.03495207849979222\n",
      "learning rate: 0.0009211086168581436\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 30\n",
      "train loss: 0.03552753185507602\n",
      "learning rate: 0.000915734806151273\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 31\n",
      "train loss: 0.03458495420810884\n",
      "learning rate: 0.0009102007217627571\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 32\n",
      "train loss: 0.03371106303982927\n",
      "learning rate: 0.000904508497187474\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 33\n",
      "train loss: 0.0336335909658831\n",
      "learning rate: 0.0008986603268863538\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 34\n",
      "train loss: 0.032981926129160524\n",
      "learning rate: 0.0008926584654403727\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 35\n",
      "train loss: 0.032453904692418205\n",
      "learning rate: 0.0008865052266813688\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 36\n",
      "train loss: 0.032312215573550344\n",
      "learning rate: 0.0008802029828000158\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 37\n",
      "train loss: 0.03212459471277491\n",
      "learning rate: 0.0008737541634312987\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 38\n",
      "train loss: 0.031997586985280414\n",
      "learning rate: 0.000867161254717843\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 39\n",
      "train loss: 0.031374120856161244\n",
      "learning rate: 0.0008604267983514597\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 40\n",
      "train loss: 0.030766901047063804\n",
      "learning rate: 0.000853553390593274\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 41\n",
      "train loss: 0.03075965756583892\n",
      "learning rate: 0.0008465436812728183\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 42\n",
      "train loss: 0.030846069845744593\n",
      "learning rate: 0.0008394003727664712\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 43\n",
      "train loss: 0.03085607073331129\n",
      "learning rate: 0.0008321262189556411\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 44\n",
      "train loss: 0.02971827655383748\n",
      "learning rate: 0.0008247240241650922\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 45\n",
      "train loss: 0.030359279498190225\n",
      "learning rate: 0.0008171966420818231\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 46\n",
      "train loss: 0.029172164973563064\n",
      "learning rate: 0.0008095469746549173\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 47\n",
      "train loss: 0.02914342131398752\n",
      "learning rate: 0.0008017779709767859\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 48\n",
      "train loss: 0.029110137852812242\n",
      "learning rate: 0.0007938926261462369\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 49\n",
      "train loss: 0.028843071897274364\n",
      "learning rate: 0.0007858939801138065\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 50\n",
      "train loss: 0.028414057333490807\n",
      "learning rate: 0.0007777851165098014\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 51\n",
      "train loss: 0.028348410195353144\n",
      "learning rate: 0.0007695691614555006\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 52\n",
      "train loss: 0.028348239484482896\n",
      "learning rate: 0.0007612492823579748\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 53\n",
      "train loss: 0.027784775652571352\n",
      "learning rate: 0.0007528286866889927\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 54\n",
      "train loss: 0.027593450983261276\n",
      "learning rate: 0.0007443106207484779\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 55\n",
      "train loss: 0.027465730425929594\n",
      "learning rate: 0.0007356983684129991\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 56\n",
      "train loss: 0.02817409118626289\n",
      "learning rate: 0.0007269952498697738\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 57\n",
      "train loss: 0.027307526197306767\n",
      "learning rate: 0.0007182046203366715\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 58\n",
      "train loss: 0.02697304729372263\n",
      "learning rate: 0.0007093298687687145\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 59\n",
      "train loss: 0.026684489480392662\n",
      "learning rate: 0.0007003744165515709\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 60\n",
      "train loss: 0.026588428904954903\n",
      "learning rate: 0.0006913417161825453\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 61\n",
      "train loss: 0.02651841224667555\n",
      "learning rate: 0.0006822352499395751\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 62\n",
      "train loss: 0.026318147482941607\n",
      "learning rate: 0.0006730585285387469\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 63\n",
      "train loss: 0.026185909553826926\n",
      "learning rate: 0.000663815089780847\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 64\n",
      "train loss: 0.02600966493771997\n",
      "learning rate: 0.0006545084971874741\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 65\n",
      "train loss: 0.025764892535830686\n",
      "learning rate: 0.0006451423386272315\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 66\n",
      "train loss: 0.02595842888433776\n",
      "learning rate: 0.0006357202249325374\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 67\n",
      "train loss: 0.025563352016319416\n",
      "learning rate: 0.0006262457885075794\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 68\n",
      "train loss: 0.025503510598115578\n",
      "learning rate: 0.0006167226819279531\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 69\n",
      "train loss: 0.02629561142850957\n",
      "learning rate: 0.0006071545765325257\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 70\n",
      "train loss: 0.025218785037760608\n",
      "learning rate: 0.0005975451610080645\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 71\n",
      "train loss: 0.025249262674973752\n",
      "learning rate: 0.0005878981399671775\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 72\n",
      "train loss: 0.024919289454237787\n",
      "learning rate: 0.0005782172325201158\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 73\n",
      "train loss: 0.02487510689785202\n",
      "learning rate: 0.0005685061708409844\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 74\n",
      "train loss: 0.02456099813815184\n",
      "learning rate: 0.0005587686987289191\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 75\n",
      "train loss: 0.024518358733081176\n",
      "learning rate: 0.0005490085701647806\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 76\n",
      "train loss: 0.024626485652061637\n",
      "learning rate: 0.0005392295478639228\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 77\n",
      "train loss: 0.02442011550559612\n",
      "learning rate: 0.0005294354018255947\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 78\n",
      "train loss: 0.02416324151490263\n",
      "learning rate: 0.0005196299078795345\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 79\n",
      "train loss: 0.023964575151661914\n",
      "learning rate: 0.0005098168462303143\n",
      "__________________________________________________________________________________________\n",
      "epoch     : 80\n",
      "train loss: 0.023903465394800653\n",
      "learning rate: 0.0005000000000000001\n",
      "__________________________________________________________________________________________\n",
      "Successfully trained?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "directory = 'results'\n",
    "\n",
    "def train_loop(results_folder , EPOCH , lr):\n",
    "    show_gpus()\n",
    "    model = DataParallel(ObjectDiscovery(encoder_resolution = (128 , 128) , decoder_resolution = (8 , 8),\n",
    "                    T = 3  , K = 7 , D_slots = 128))\n",
    "    model.to(device)\n",
    "    optimizer = Adam(model.parameters() , lr = lr)\n",
    "    criterion = MSELoss()\n",
    "    scheduler = CosineAnnealingLR(optimizer , T_max = 160)\n",
    "    for epoch in range(0 , EPOCH):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        print(f\"epoch     : {epoch + 1}\")\n",
    "        for images  in train_loader:\n",
    "            images = images.to(device)\n",
    "            reconst = model(images)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(reconst , images)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"train loss: {train_loss}\")\n",
    "        print(f'learning rate:' , optimizer.param_groups[0]['lr'])\n",
    "        print(\"__________________________________________________________________________________________\")\n",
    "        save_model(epoch , model , optimizer , train_loss  , path = f'{directory}/model_{epoch + 1}')\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "create_directory(directory)\n",
    "train_loop(results_folder = directory , EPOCH = 80 , lr = 0.001)\n",
    "print(\"Successfully trained?\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4940312,
     "sourceId": 8316985,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 33522.489173,
   "end_time": "2024-05-05T15:10:42.001635",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-05T05:51:59.512462",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
